# Распределенные системы
## Что такое бэкенд?
![alt text](images_BDS/1.png)
![alt text](images_BDS/2.png)

**Требования к надеждности:**
1) Регламентирована доступность
2) Спланирована нагрузка

Обычно доступность оценивают с точки зрения SLA
![alt text](images_BDS/3.png)

Как бы классно мы не писали код, как бы надежен не был наш бэкенд, всегда нужно помнить, что есть какие-то комплектующие в датацентре, которые в любой момент могут просто взять и отказать
Надежность бэкенда - это функция, которая зависит от надежности каждого из его компонентов

### Типичный проект
![alt text](images_BDS/4.png)

Бэкенд может отказаться, балансер перенаправит нагрузку на оставшийся, но оставшийся бэкенд может сломаться от двойной нагрузки и тоже сломаться
![alt text](images_BDS/5.png)

Вроде бы все хорошо, но на самом деле не очень
![alt text](images_BDS/6.png)

Если сервисы будут расположены в одной зоне доступности, то в случае каких-то проблем в ней, проблемы заденут в целом все сервисы в этой зоне доступности, ну или в лучшем случае частично. Лучше разделять сервисы еще на две части
![alt text](images_BDS/7.png)


## CAP Теорема
[Теорема CAP](https://ru.wikipedia.org/wiki/Теорема_CAP) (известная также как теорема Брюера) — эвристическое утверждение о том, что в любой реализации [распределённых вычислений](https://ru.wikipedia.org/wiki/Распределённые_вычисления) возможно обеспечить не более двух из трёх следующих свойств:
* [согласованность данных](https://ru.wikipedia.org/wiki/Согласованность_данных) (англ. consistency) — во всех вычислительных узлах в один момент времени данные не противоречат друг другу;
* [доступность](https://ru.wikipedia.org/wiki/Доступность_информации) (англ. availability) — любой запрос к распределённой системе завершается откликом, однако без гарантии, что ответы всех узлов системы совпадают;
* устойчивость к фрагментации (англ. partition tolerance) — расщепление распределённой системы на несколько изолированных секций не приводит к некорректности отклика от каждой из секций.

![alt text](images_BDS/8.png)

**Пример 1:**
![alt text](images_BDS/9.png)
Все ок, пока Node 2 не вернется в систему. Мы не можем этим узлом отвечать, потому что пока этот узел был недоступен, он был оторван от внешнего мира, и он не сможет поддерживать консистентность в тот момент, когда он возвращается. Поэтому вся система отказывает и ждет какого-то вмешательства со стороны
![alt text](images_BDS/10.png)

**Пример 2:**
![alt text](images_BDS/11.png)
Опять же отказывает узел 2, узел 1 и 3 продолжают отвечать, затем восстанавливается узел 2 и успешно отвечать чем-то не тем.
![alt text](images_BDS/12.png)

**Пример 3:**
![alt text](images_BDS/13.png)
Опять же отказывает узел 2, узел 1 и 3 продолжают отвечать (иначе бы нарушалась доступность). Затем узел 2 восстанавливается и какие исходы могут быть:
Узел 2 не отвечает (если бы узел отвечал, то мы бы потеряли консистентность). При этом, если мы полностью отказываем, тогда мы теряем доступность

Вывод простой: при разделении любая система либо доступна, либо консистентна. Поэтому система, которая одновременно доступна и консистентна, но неустойчива к разделениям, не существует
## Eventual Consistency
[Согласованность в конечном счёте](https://ru.wikipedia.org/wiki/Согласованность_в_конечном_счёте) (англ. eventual consistency) — одна из моделей согласованности, используемая в распределённых системах для достижения высокой доступности, в рамках которой гарантируется, что в отсутствии изменений данных, через какой-то промежуток времени после последнего обновления («в конечном счёте») все запросы будут возвращать последнее обновлённое значение.
Пример согласованной в конечном счёте системы — DNS: обновлённая DNS-запись распространяется в соответствии с настройками интервалов кэширования серверов и, хоть и не моментально, но в конечном счёте все клиенты увидят обновление.
Простыми словами — изменения применяются гарантированно, но с возможной задержкой (асинхронно).

![alt text](images_BDS/14.png)

![alt text](images_BDS/15.png)
![alt text](images_BDS/16.png)
![alt text](images_BDS/17.png)


## Распределенные СУБД
Если откажет реплика, то она недоступна
![alt text](images_BDS/18.png)


![alt text](images_BDS/19.png)

### Партицирование
![alt text](images_BDS/20.png)
![alt text](images_BDS/21.png)

*Партицирование - делим данные на несколько серверов*

## Репликация
[Репликация](https://ru.wikipedia.org/wiki/Репликация_(вычислительная_техника)) (англ. replication) — механизм синхронизации содержимого нескольких копий объекта (например, содержимого базы данных). Репликация — это процесс, под которым понимается копирование данных из одного источника на другой (или на множество других) и наоборот.
При репликации изменения, сделанные в одной копии объекта, могут быть распространены в другие копии.
Примером программного решения может являться DRBD — блочное устройство, предназначенное для построения отказоустойчивых кластерных систем на операционной системе с ядром Linux.

*Репликация - одни и те же данные дублируются на все сервера*

![alt text](images_BDS/23.png)
![alt text](images_BDS/24.png)
![alt text](images_BDS/25.png)

![alt text](images_BDS/26.png)
![alt text](images_BDS/27.png)
![alt text](images_BDS/28.png)

## Восемь заблуждений распределенных систем
### Сеть надежна
![alt text](images_BDS/29.png)
![alt text](images_BDS/30.png)

### Задержка равна нулю
![alt text](images_BDS/31.png)
![alt text](images_BDS/32.png)

### Канал передачи данных "очень широкий"
![alt text](images_BDS/33.png)
![alt text](images_BDS/34.png)


### Сеть безопасна
![alt text](images_BDS/35.png)
![alt text](images_BDS/36.png)

### Топология сети не поменяется
![alt text](images_BDS/37.png)
![alt text](images_BDS/38.png)

### Есть один администратор
![alt text](images_BDS/39.png)
![alt text](images_BDS/40.png)

### Транспортные расходы равны нулю
![alt text](images_BDS/41.png)
![alt text](images_BDS/42.png)

### Сеть гомогенна
![alt text](images_BDS/43.png)
![alt text](images_BDS/44.png)

## Паттерны проектирования
### Идемпотентность
[Идемпоте́нтность](https://ru.wikipedia.org/wiki/Идемпотентность) («равносильность» от лат. idem «тот же самый» + potens «способный») — свойство объекта или операции при повторном применении операции к объекту давать тот же результат, что и при первом. Термин предложил американский математик Бенджамин Пирс (англ. Benjamin Peirce) в статьях 1870-х годов.

Зачем вообще нужна идемпотентность?
![alt text](images_BDS/45.png)
![alt text](images_BDS/46.png)
![alt text](images_BDS/47.png)
*А еще может быть не 200, а 503*

Вывод: абсолютно идемпотентного API создать не получится

### Компромиссы при идемпотентности
![alt text](images_BDS/48.png)

Даже такие гарантии не решают проблемы с идемпотентностью
![alt text](images_BDS/49.png)

### Idempotency Key in SOA (Service Oriented Architecture)
![alt text](images_BDS/50.png)
![alt text](images_BDS/51.png)

### Кэш
![alt text](images_BDS/52.png)
![alt text](images_BDS/53.png)
![alt text](images_BDS/54.png)
![alt text](images_BDS/55.png)

![alt text](images_BDS/56.png)
![alt text](images_BDS/57.png)

### Повторы
![alt text](images_BDS/58.png)
![alt text](images_BDS/59.png)

### Предохранитель (circuit breaker)
![alt text](images_BDS/60.png)
![alt text](images_BDS/61.png)
![alt text](images_BDS/62.png)
![alt text](images_BDS/63.png)

### Асинхронные запросы
![alt text](images_BDS/64.png)

### Другие паттерны проектирования
[На английском](https://learn.microsoft.com/en-us/azure/architecture/patterns/)

Книга, в которой много паттернов (+ много используется в яшке)
![alt text](images_BDS/65.png)