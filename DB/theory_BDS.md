# Базы данных
## Обзор СУБД
Какие бывают базы данных?
* Key-value
* Документоориентированные
* Реляционные
### Key-value
![alt text](images/1.png)
### Документоориентированные
![alt text](images/2.png)
### Реляционные СУБД
Обычно используется SQL язык
![alt text](images/3.png)
![alt text](images/4.png)
![alt text](images/5.png)
![alt text](images/6.png)
### Кейс "Наш Маркет"
Будем использовать [PostgreSQL](https://ru.wikipedia.org/wiki/PostgreSQL) (потому что самая популярная БД в яшке)
![alt text](images/7.png)
![alt text](images/8.png)

**Первый инструмет**
![alt text](images/9.png)

**Второй инструмент**
![alt text](images/10.png)

![alt text](images/11.png)
## Индексы
*Как работает поиск по индексу?*

**Первая задача**
![alt text](images/12.png)
![alt text](images/13.png)
Что же здесь может пойти не так?
![alt text](images/14.png)
340ms - долго
Seq Scan - это просто последовательный поиск
![alt text](images/15.png)
Таким образом, сложностть поиска в такой таблице - $O(N)$

Что же сделать? Можно применить индексы:
![alt text](images/16.png)
order_id является первичным ключом, и по умолчанию БД сразу строим по нему индекс, потому что по первичному ключу всегда ищутся записи. Но точно так же мы можем построить индекс по любому другому полю и искать по нему
![alt text](images/17.png)
![alt text](images/18.png)
Но есть ограничения: если для нашей таблицы создадим индекс по хеш таблице, то система выделит всего 5 статусов, и для каждого статуса будет список из большого количества записей, поэтому польза от такого индекса будет небольшая
![alt text](images/19.png)

**Задача 2:**
![alt text](images/20.png)
![alt text](images/21.png)
![alt text](images/22.png)
![alt text](images/23.png)

Можно построить полнотекстовый индекс: для этого надо векторизовать данные для построения полнотекстового индекса
![alt text](images/24.png)
![alt text](images/25.png)

**Задача 3:**
![alt text](images/26.png)
![alt text](images/27.png)
![alt text](images/28.png)
![alt text](images/29.png)

![alt text](images/30.png)
Кластерные индексы - это те индексы, которые располагаются непосредственно с самими данными (как правило, это primary key)
Некластерные индексы - это те индексы, которые могут находиться отдельно
Индексы помогают контролировать уникальность: к примеру, primary key уникален
Как правило, вычисляемые индексы используются в постгресе при поиске подстрок. Есть MySQL и PostgreSQL: одно из главных отличий между ними - это то, что поиск по подстроке в MySQL регистронезависимый, а PostgreSQL поиск регистрозависимый (и чтобы сделать поиск регистронезависимым, нужно применить функции преобразования значения в верхний/нижний регистр)

![alt text](images/31.png)

## Материализованные представления
**Задача 4:**
![alt text](images/32.png)
![alt text](images/33.png)
![alt text](images/34.png)

Как можно улучшить этот запрос? Мы можем избавиться от Seq Scan, добавив индекс
![alt text](images/35.png)
Но запрос все равно остается тяжелым

Как можно еще ускорить? Мы можем создать материализованное представление, в котором система будет хранить уже рассчитанное значение, и таким образом скорость работы нашего приложения вырастет
![alt text](images/36.png)
Мы не будем больше рассчитывать min и max, и периодически будем обновлять это значение
![alt text](images/37.png)
Один из подводных камней - это вынесение бизнес логики. Очень редко, когда реализовывается бизнес логика на уровне БД, стараются все делать в коде. Но иногда мы можем создать миграцию, которая облегчит жизнь нашим пользователям, и они будут получать более достоверную информацию быстрее

Помимо материализованных представлений, которые хранятся на диске, есть еще и временные представления, которые хранятся в памяти, и их можно использовать при формировании сложных запросов
## Транзакции
*Что такое транзакция? Когда теряются данные?*

![alt text](images/38.png)
Когда разработчик начинает разбираться, что же такое транзакция, как они используются и какие есть нюансы? Прежде всего когда начинаются какие-то проблемы. До этого момента мы могли использовать планировщик запросов и все понятно: мы строим план запросов, он показывает, как выполнился запрос: по индексу/не по индексу, скорость выполнения и т.д.. Но периодически начинают возникать проблемы: например, когда происходят двойные списания или двойные начисления, и начинает разрушаться баланс

![alt text](images/39.png)
![alt text](images/40.png)
Видим Seq Scan, т.е. запрос работает долго. Что это значит? Когда к нам приходит много пользователей, у нас может возникнуть некоторая гонка между исполнением этих запросов. Соответственно, 26ms это долго. Ускорим его:
![alt text](images/41.png)
Ускоряем запрос, добавляем индексы, получаем прирост производительности в 130 раз, но все равно проблема сохраняется, но стала гораздо реже

Почему у нас могут происходить двойные списания?
![alt text](images/42.png)
Любой запрос - это транзакция, некоторая операция, которая выполняется в БД.
![alt text](images/43.png)
Для того, чтобы всем этим управлять, в БД есть различные уровни изоляции
![alt text](images/44.png)
*Опечатка: Serializable - последовательное чтение*

![alt text](images/45.png)
![alt text](images/46.png)
![alt text](images/47.png)
![alt text](images/48.png)
Мы можем управлять уровнями изоляций транзакций для того, чтобы решить проблему гонок между различными транзакциями
С помощью уровней изоляции мы можем решить проблему списаний/проблему начислений, система будет гарантировать, что никаких пересекающихся событий и изменений не произошло

## Блокировки
Но пользователи могут выполнять действия в системе, а получат информацию о том, что что-то пошло не так
![alt text](images/49.png)
Для этого нам поможет механизм блокировок
![alt text](images/50.png)
![alt text](images/51.png)
![alt text](images/52.png)
Как можно решить Deadlock? Нужно ввести некоторые правила:
* Захват ресурсов следует делать в каком-то порядке: сортировка по ключам (если мы захватываем данные в одной и той же таблице), либо если мы работаем с разными таблицами, то нужно захватывать ресурсы в этих таблицах по алфавиту (есть customers и orders, сначала захватываем customers, затем orders)

Для того, чтобы сделать списание чуть лучше, мы можем перед изменением записи добавить ключ FOR UPDATE
![alt text](images/53.png)

## Денормализация
*Зачем нужна денормализация?*

Нормализация - это очень важный процесс проектирования БД, но иногда (редко, но встречается) создать повторяющиеся записи, в одной ячейке хранить несколько записей, для того, чтобы связанные данные хранить как можно ближе, и тем самым ускорить выполнение запросов

![alt text](images/54.png)
![alt text](images/55.png)
![alt text](images/56.png)

Один из вариантов решения проблемы: создать доп. таблицу, в которой будут храниться денормализованные данные, либо эти данные хранить рядом с теми записями, которые мы регулярно используем
![alt text](images/57.png)

Какой плюс хранения отдельно? Как правило, денормализованные данные имеют либо временное назначение (например, для отгрузки хранить эти значения, мы отгрузили эти товары, и эти денормализованные данные нам не нужны), либо мы можем для историчности хранить данные рядом (например, у нас есть имя покупателя - Денис, и мы можем указать, что имя покупателя было Денис. Таким образом, у нас таблица заказов будет очень большой, но при этом, если покупатель переименуется, в таблице заказов будет явно написано, что в этот момент покупатель назывался Денис. Таким образом, сохраним историчность)
![alt text](images/58.png)

## Масштаб-ирование
### Вертикальное масштабирование
Если наша система медленно работает, не справляется с нагрузкой, то дайте побольше памяти, и помощнее процессоры, и диски побыстрее 
### Репликация
Когда эти самые простые инструменты исчерпаны, мы можем начать применять другие подходы, например **репликацию**
Когда у нас уже большой проект, мы понимаем, как он используется, что у нас большое количество запросов на чтение, меньшее количество запросов на запись, много пользователей
![alt text](images/59.png) 

Разделим операции на чтение и на запись
![alt text](images/60.png)
Разделение можно сделать на уровне приложения: добавим слой пул коннекторов, которые будут работать либо с репликами, либо с мастером
PostgreSQL использует репликацию, и все изменения в мастере он умеет синхронно и асинхронно доставлять до реплик
Что означает синхронно и асинхронно?
Синхронно означает, что при доставке данных PostgreSQL ожидает, что реплика пришлет подтверждение, что она получила данные, и в этот момент процесс доставки данных завершен, и он отправляет следующий порцию данных
Асинхронно означает, что он отправляет данные и не ждет, когда она вернется обратно
Таким образом, при использовании конфигураций синхронных и асинхронных реплик, у нас могут возникнуть данные из будущего, когда мы поместили какие-то изменения в мастер: они долетели до асинхронной реплики, а в синхронную реплику они еще не записались, и при выполнении запроса мы можем получить данные из будущего, которые еще до конца не долетели, но мы их уже начали в репликах использовать.

![alt text](images/61.png)
![alt text](images/62.png)

### Шардирование
Что делать, если и репликация нам не помогает? Допустим, у нас очень много данных
Используем шардирование запросов: у нас есть большая таблица, и мы можем подумать, как разделить ее на маленькие части
Например у нас есть таблица заказов, и мы можем разделить ее на части по периодам заказов. Таким образом, у нас эти шарды будут иметь меньшее значение
Можно применять другую стратегию: если у нас есть первичный ключ, мы можем придумать некоторую функцию, которая нам будет делить этот ключ, например, по остатку: если возьмем число 10, то по остатку 0..9 мы сможем выделить отдельные шарды и на этих шардах хранить данные вот по такой хитрой схеме.
Для чего нужны шарды и почему они влияют на скорость выполнения запросов? Когда мы разделяем одну большую таблицу на много маленьких таблиц, мы ускоряем работу этих таблиц

Можем комбинировать разные подходы:
![alt text](images/63.png)

![alt text](images/65.png)

## Отказоустойчивость
![alt text](images/66.png)
Чем плох этот подход? Если у нас всего 1 реплика и 1 мастер, то у нас в 2 раза больше запросов станет в мастер, и скорее всего тоже начнет отказывать. Поэтому при наличие реплик лучше делать количество реплик хотя бы 2, а лучше больше
![alt text](images/67.png)
![alt text](images/68.png)

## Безопасность
После всего этого нам нужно убедиться, что система безопасна
![alt text](images/69.png)

# Работа с БД из приложения и миграции
